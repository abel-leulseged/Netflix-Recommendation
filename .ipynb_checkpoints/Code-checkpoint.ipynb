{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df2d4c0e4aa5ba8fb404e822fccb14d8cf7b431f"
   },
   "source": [
    "1. [Import Libraries](#Import-Libraries)\n",
    "1. [Load and Preprocess Netflix Data](#Load-Data)\n",
    "1. [When Were The Movies Released?](#Movie-Release-Timeline)\n",
    "1. [How Are The Ratings Distributed?](#Rating-Distribution)\n",
    "1. [When Have The Movies Been Rated?](#Movie-has-been-rated)\n",
    "1. [How Are The Number Of Ratings Distributed For The Movies And The Users?](#Ratings-Distributed-MoviesvsUsers)\n",
    "1. [Filter Sparse Movies And Users](#Filter-Sparse-MovieUsers )\n",
    "1. [Create Train- And Testset](#Create-Train&Test)\n",
    "1. [Transform The User-Ratings To User-Movie-Matrix](#User-Ratings-To-User-Movie-Matrix)\n",
    "1. [Recommendation Engines](#Recommender-Engine)\n",
    "    1. [Mean Rating](#Mean-Rating)\n",
    "    1. [Weighted Mean Rating](#Weighted-Mean-Rating)\n",
    "    1. [Cosine User-User Similarity](#Cosine-User-User-Similarity)\n",
    "    1. [Cosine TFIDF Movie Description Similarity](#TFIDF-MovieDescription-Similarity)\n",
    "    1. [Matrix Factorisation With Keras And Gradient Descent](#Matrix-Factorisation-Keras-And-Gradient-Descent)\n",
    "    1. [Deep Learning With Keras](#Deep-Learning-With-Keras)\n",
    "    1. [Deep Hybrid System With Metadata And Keras](#Deep-Hybrid-System-With-Metadata-And-Keras)\n",
    "1. [Exploring Python Libraries](#Exploring-Python-Libraries)\n",
    "    1. [Surprise Library](#Surprise-Library)\n",
    "1. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8949ab1db8578ac7d492f01b0e784f1787d5669"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "036c8636d06aac7b12c61671112aa6441141986b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To store the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# To create interactive plots\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# To shift lists\n",
    "from collections import deque\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# To use recommender systems\n",
    "import surprise as sp\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# To create deep learning models\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To create sparse matrices\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# To light fm\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "892c6c6e4ef6e7f0638dfec8d2b439c27a46300d"
   },
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "8dc354230a8ffbba52f93b55975edb5ad3d18289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Movie-Titles:\t(17770, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15831</th>\n",
       "      <td>1996.0</td>\n",
       "      <td>The Other Side of Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>1966.0</td>\n",
       "      <td>La Guerre Est Finie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>1969.0</td>\n",
       "      <td>The Butcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>The Favor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14492</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>Forever Knight: The Trilogy: Part 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16513</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>The Sandy Bottom Orchestra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>1994.0</td>\n",
       "      <td>Farinelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>The Way We Live Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15222</th>\n",
       "      <td>1986.0</td>\n",
       "      <td>The Guyver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>The Great Outdoors</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year                                 Name\n",
       "Id                                                \n",
       "15831  1996.0             The Other Side of Sunday\n",
       "9374   1966.0                  La Guerre Est Finie\n",
       "3114   1969.0                          The Butcher\n",
       "999    1994.0                            The Favor\n",
       "14492  1994.0  Forever Knight: The Trilogy: Part 2\n",
       "16513  2001.0           The Sandy Bottom Orchestra\n",
       "1834   1994.0                            Farinelli\n",
       "5941   2001.0                  The Way We Live Now\n",
       "15222  1986.0                           The Guyver\n",
       "4977   1988.0                   The Great Outdoors"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data for all movies\n",
    "movie_titles = pd.read_csv('../netflix-prize-data/movie_titles.csv', \n",
    "                           encoding = 'ISO-8859-1', \n",
    "                           header = None, \n",
    "                           names = ['Id', 'Year', 'Name']).set_index('Id')\n",
    "\n",
    "print('Shape Movie-Titles:\\t{}'.format(movie_titles.shape))\n",
    "movie_titles.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b9d560b1d911504963e0785c4dc5ca33841677a"
   },
   "source": [
    "---\n",
    "There are roughly **18.000** movies in the ratings dataset and the metadata for the movies contains only the release date and the movie title.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35ef2566256628c461bf8f08bfbd7bc9c4f4920b"
   },
   "outputs": [],
   "source": [
    "# Load a movie metadata dataset\n",
    "movie_metadata = pd.read_csv('../input/the-movies-dataset/movies_metadata.csv', low_memory=False)[['original_title', 'overview', 'vote_count']].set_index('original_title').dropna()\n",
    "# Remove the long tail of rarly rated moves\n",
    "movie_metadata = movie_metadata[movie_metadata['vote_count']>10].drop('vote_count', axis=1)\n",
    "\n",
    "print('Shape Movie-Metadata:\\t{}'.format(movie_metadata.shape))\n",
    "movie_metadata.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d3178c905946971647375ac7805b1fc7148ef6a"
   },
   "source": [
    "---\n",
    "About **21.000** entries are in the movie metadata dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a4f51ade6fd7c9172f3e8fcb2ba67e67e88b055"
   },
   "source": [
    "## Userdata and Data Stracture\n",
    "The user-data structure has to be preprocessed to extract all ratings and form a matrix, since the file-structure is a messy mixture of json and csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "3c3e12a31f4ec138702e5fa0ea86f7395309ef3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape User-Ratings:\t(24053764, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1628479</th>\n",
       "      <td>2195565</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2003-10-30</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6916733</th>\n",
       "      <td>1627882</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2005-07-28</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18431349</th>\n",
       "      <td>83150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004-04-16</td>\n",
       "      <td>3526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15284630</th>\n",
       "      <td>133670</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-04-11</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13844683</th>\n",
       "      <td>434075</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2002-12-19</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280193</th>\n",
       "      <td>967999</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2005-07-01</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610713</th>\n",
       "      <td>788170</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2004-08-24</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23896956</th>\n",
       "      <td>1706866</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>4472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18543745</th>\n",
       "      <td>2476717</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2004-10-02</td>\n",
       "      <td>3541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323754</th>\n",
       "      <td>2527680</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2003-12-23</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             User  Rating        Date  Movie\n",
       "1628479   2195565     3.0  2003-10-30    313\n",
       "6916733   1627882     5.0  2005-07-28   1370\n",
       "18431349    83150     3.0  2004-04-16   3526\n",
       "15284630   133670     3.0  2005-04-11   2937\n",
       "13844683   434075     5.0  2002-12-19   2660\n",
       "3280193    967999     3.0  2005-07-01    607\n",
       "3610713    788170     3.0  2004-08-24    692\n",
       "23896956  1706866     4.0  2005-09-11   4472\n",
       "18543745  2476717     5.0  2004-10-02   3541\n",
       "2323754   2527680     3.0  2003-12-23    443"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The user-data structure has to be preprocessed to extract all ratings and form a matrix, since the file-structure is a messy mixture of json and csv.\n",
    "\n",
    "# Load single data-file\n",
    "df_raw = pd.read_csv('../netflix-prize-data/combined_data_1.txt', header=None, names=['User', 'Rating', 'Date'], usecols=[0, 1, 2])\n",
    "\n",
    "\n",
    "# Find empty rows to slice dataframe for each movie\n",
    "tmp_movies = df_raw[df_raw['Rating'].isna()]['User'].reset_index()\n",
    "movie_indices = [[index, int(movie[:-1])] for index, movie in tmp_movies.values]\n",
    "\n",
    "# Shift the movie_indices by one to get start and endpoints of all movies\n",
    "shifted_movie_indices = deque(movie_indices)\n",
    "shifted_movie_indices.rotate(-1)\n",
    "\n",
    "\n",
    "# Gather all dataframes\n",
    "user_data = []\n",
    "\n",
    "# Iterate over all movies\n",
    "for [df_id_1, movie_id], [df_id_2, next_movie_id] in zip(movie_indices, shifted_movie_indices):\n",
    "    \n",
    "    # Check if it is the last movie in the file\n",
    "    if df_id_1<df_id_2:\n",
    "        tmp_df = df_raw.loc[df_id_1+1:df_id_2-1].copy()\n",
    "    else:\n",
    "        tmp_df = df_raw.loc[df_id_1+1:].copy()\n",
    "        \n",
    "    # Create movie_id column\n",
    "    tmp_df['Movie'] = movie_id\n",
    "    \n",
    "    # Append dataframe to list\n",
    "    user_data.append(tmp_df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df = pd.concat(user_data)\n",
    "del user_data, df_raw, tmp_movies, tmp_df, shifted_movie_indices, movie_indices, df_id_1, movie_id, df_id_2, next_movie_id\n",
    "print('Shape User-Ratings:\\t{}'.format(df.shape))\n",
    "df.sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8cb7056604f7e435022167c689a2533e1e21e24"
   },
   "source": [
    "\n",
    "There are about ***24,000,000*** different ratings.\n",
    "I loaded only a single file of four to reduce memory footprint and accelerate computation. Keep in mind that this approach could introduce biases in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac25c2532c29e23d2855e4a7294b076c0696342e"
   },
   "source": [
    "## Movie Release Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "ea5e1bdcfb83754dab86a12da1b8b4cc320563d6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "scatter",
         "uid": "f2ac78be-b652-43b2-82be-726788c50200",
         "x": [
          1896,
          1909,
          1914,
          1915,
          1916,
          1917,
          1918,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940,
          1941,
          1942,
          1943,
          1944,
          1945,
          1946,
          1947,
          1948,
          1949,
          1950,
          1951,
          1952,
          1953,
          1954,
          1955,
          1956,
          1957,
          1958,
          1959,
          1960,
          1961,
          1962,
          1963,
          1964,
          1965,
          1966,
          1967,
          1968,
          1969,
          1970,
          1971,
          1972,
          1973,
          1974,
          1975,
          1976,
          1977,
          1978,
          1979,
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005
         ],
         "y": [
          1,
          1,
          2,
          5,
          4,
          3,
          2,
          8,
          6,
          9,
          6,
          2,
          4,
          12,
          9,
          13,
          10,
          10,
          13,
          13,
          22,
          15,
          26,
          16,
          29,
          27,
          21,
          37,
          34,
          33,
          33,
          33,
          36,
          37,
          39,
          37,
          36,
          41,
          41,
          42,
          50,
          47,
          59,
          64,
          47,
          78,
          61,
          72,
          87,
          72,
          96,
          95,
          95,
          101,
          96,
          91,
          113,
          106,
          95,
          110,
          135,
          140,
          144,
          125,
          129,
          125,
          148,
          158,
          166,
          154,
          165,
          182,
          189,
          226,
          228,
          267,
          283,
          276,
          296,
          316,
          342,
          376,
          459,
          490,
          533,
          653,
          743,
          965,
          1234,
          1184,
          1310,
          1271,
          1436,
          512
         ]
        }
       ],
       "layout": {
        "title": "17770 Movies Grouped By Year Of Release",
        "xaxis": {
         "title": "Release Year"
        },
        "yaxis": {
         "title": "Movies"
        }
       }
      },
      "text/html": [
       "<div id=\"2be9a5d0-62ad-4b45-8f03-73d6b27c5cf1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2be9a5d0-62ad-4b45-8f03-73d6b27c5cf1\", [{\"x\": [1896.0, 1909.0, 1914.0, 1915.0, 1916.0, 1917.0, 1918.0, 1919.0, 1920.0, 1921.0, 1922.0, 1923.0, 1924.0, 1925.0, 1926.0, 1927.0, 1928.0, 1929.0, 1930.0, 1931.0, 1932.0, 1933.0, 1934.0, 1935.0, 1936.0, 1937.0, 1938.0, 1939.0, 1940.0, 1941.0, 1942.0, 1943.0, 1944.0, 1945.0, 1946.0, 1947.0, 1948.0, 1949.0, 1950.0, 1951.0, 1952.0, 1953.0, 1954.0, 1955.0, 1956.0, 1957.0, 1958.0, 1959.0, 1960.0, 1961.0, 1962.0, 1963.0, 1964.0, 1965.0, 1966.0, 1967.0, 1968.0, 1969.0, 1970.0, 1971.0, 1972.0, 1973.0, 1974.0, 1975.0, 1976.0, 1977.0, 1978.0, 1979.0, 1980.0, 1981.0, 1982.0, 1983.0, 1984.0, 1985.0, 1986.0, 1987.0, 1988.0, 1989.0, 1990.0, 1991.0, 1992.0, 1993.0, 1994.0, 1995.0, 1996.0, 1997.0, 1998.0, 1999.0, 2000.0, 2001.0, 2002.0, 2003.0, 2004.0, 2005.0], \"y\": [1, 1, 2, 5, 4, 3, 2, 8, 6, 9, 6, 2, 4, 12, 9, 13, 10, 10, 13, 13, 22, 15, 26, 16, 29, 27, 21, 37, 34, 33, 33, 33, 36, 37, 39, 37, 36, 41, 41, 42, 50, 47, 59, 64, 47, 78, 61, 72, 87, 72, 96, 95, 95, 101, 96, 91, 113, 106, 95, 110, 135, 140, 144, 125, 129, 125, 148, 158, 166, 154, 165, 182, 189, 226, 228, 267, 283, 276, 296, 316, 342, 376, 459, 490, 533, 653, 743, 965, 1234, 1184, 1310, 1271, 1436, 512], \"type\": \"scatter\", \"uid\": \"f2ac78be-b652-43b2-82be-726788c50200\"}], {\"title\": \"17770 Movies Grouped By Year Of Release\", \"xaxis\": {\"title\": \"Release Year\"}, \"yaxis\": {\"title\": \"Movies\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"2be9a5d0-62ad-4b45-8f03-73d6b27c5cf1\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"2be9a5d0-62ad-4b45-8f03-73d6b27c5cf1\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2be9a5d0-62ad-4b45-8f03-73d6b27c5cf1\", [{\"x\": [1896.0, 1909.0, 1914.0, 1915.0, 1916.0, 1917.0, 1918.0, 1919.0, 1920.0, 1921.0, 1922.0, 1923.0, 1924.0, 1925.0, 1926.0, 1927.0, 1928.0, 1929.0, 1930.0, 1931.0, 1932.0, 1933.0, 1934.0, 1935.0, 1936.0, 1937.0, 1938.0, 1939.0, 1940.0, 1941.0, 1942.0, 1943.0, 1944.0, 1945.0, 1946.0, 1947.0, 1948.0, 1949.0, 1950.0, 1951.0, 1952.0, 1953.0, 1954.0, 1955.0, 1956.0, 1957.0, 1958.0, 1959.0, 1960.0, 1961.0, 1962.0, 1963.0, 1964.0, 1965.0, 1966.0, 1967.0, 1968.0, 1969.0, 1970.0, 1971.0, 1972.0, 1973.0, 1974.0, 1975.0, 1976.0, 1977.0, 1978.0, 1979.0, 1980.0, 1981.0, 1982.0, 1983.0, 1984.0, 1985.0, 1986.0, 1987.0, 1988.0, 1989.0, 1990.0, 1991.0, 1992.0, 1993.0, 1994.0, 1995.0, 1996.0, 1997.0, 1998.0, 1999.0, 2000.0, 2001.0, 2002.0, 2003.0, 2004.0, 2005.0], \"y\": [1, 1, 2, 5, 4, 3, 2, 8, 6, 9, 6, 2, 4, 12, 9, 13, 10, 10, 13, 13, 22, 15, 26, 16, 29, 27, 21, 37, 34, 33, 33, 33, 36, 37, 39, 37, 36, 41, 41, 42, 50, 47, 59, 64, 47, 78, 61, 72, 87, 72, 96, 95, 95, 101, 96, 91, 113, 106, 95, 110, 135, 140, 144, 125, 129, 125, 148, 158, 166, 154, 165, 182, 189, 226, 228, 267, 283, 276, 296, 316, 342, 376, 459, 490, 533, 653, 743, 965, 1234, 1184, 1310, 1271, 1436, 512], \"type\": \"scatter\", \"uid\": \"f2ac78be-b652-43b2-82be-726788c50200\"}], {\"title\": \"17770 Movies Grouped By Year Of Release\", \"xaxis\": {\"title\": \"Release Year\"}, \"yaxis\": {\"title\": \"Movies\"}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"2be9a5d0-62ad-4b45-8f03-73d6b27c5cf1\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data\n",
    "data = movie_titles['Year'].value_counts().sort_index()\n",
    "\n",
    "# Create trace\n",
    "trace = go.Scatter(x = data.index,\n",
    "                   y = data.values,\n",
    "                    )\n",
    "# Create layout\n",
    "layout = dict(title = '{} Movies Grouped By Year Of Release'.format(movie_titles.shape[0]),\n",
    "              xaxis = dict(title = 'Release Year'),\n",
    "              yaxis = dict(title = 'Movies'))\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bcd3bc52959d07d16c748d58c66957fc8df501bf"
   },
   "source": [
    "---\n",
    "Many movies on Netflix have been released in this millennial. Whether Netflix prefers young movies or there are no old movies left can not be deduced from this plot.The decline for the rightmost point is probably caused by an incomplete last year.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c0bd1e69ea36d80efda3cb496454fbef1c8547a"
   },
   "source": [
    "## Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8227be231769949d2ebc7f11ee11aaf7d459fe8"
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "data = df['Rating'].value_counts().sort_index(ascending=False)\n",
    "\n",
    "# Create trace\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / df.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "# Create layout\n",
    "layout = dict(title = 'Distribution Of {} Netflix-Ratings'.format(df.shape[0]),\n",
    "              xaxis = dict(title = 'Rating'),\n",
    "              yaxis = dict(title = 'Count'))\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "850e0ead10808d8ebf041e7aeb0fa487458bacb0"
   },
   "source": [
    "---\n",
    "Netflix movies rarely have a rating lower than three. Most ratings have between **three and four stars.**\n",
    "The distribution is probably biased, since only people liking the movies proceed to be customers and others presumably will leave the platform.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2a14aa4854fd058a14b08866478fb9c96c849497"
   },
   "source": [
    "## Movie has been rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e51d6cb76101a15502f39eeddb7c653fa087e612"
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "data = df['Date'].value_counts()\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "# Create trace\n",
    "trace = go.Scatter(x = data.index,\n",
    "                   y = data.values,\n",
    "                  )\n",
    "# Create layout\n",
    "layout = dict(title = '{} Movie-Ratings Grouped By Day'.format(df.shape[0]),\n",
    "              xaxis = dict(title = 'Date'),\n",
    "              yaxis = dict(title = 'Ratings'))\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d0d54dd1fe9d81b4cb744acdd77313be860775cb"
   },
   "source": [
    "# Ratings Distributed MoviesvsUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16c5d3283d54b737efe32ea4788ebca860095415"
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "data = df.groupby('Movie')['Rating'].count().clip(upper=9999)\n",
    "\n",
    "# Create trace\n",
    "trace = go.Histogram(x = data.values,\n",
    "                     name = 'Ratings',\n",
    "                     xbins = dict(start = 0,\n",
    "                                  end = 10000,\n",
    "                                  size = 100),\n",
    "                     marker = dict(color = '#db0000'))\n",
    "# Create layout\n",
    "layout = go.Layout(title = 'Distribution Of Ratings Per Movie (Clipped at 9999)',\n",
    "                   xaxis = dict(title = 'Ratings Per Movie'),\n",
    "                   yaxis = dict(title = 'Count'),\n",
    "                   bargap = 0.2)\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)\n",
    "\n",
    "\n",
    "\n",
    "##### Ratings Per User #####\n",
    "# Get data\n",
    "data = df.groupby('User')['Rating'].count().clip(upper=199)\n",
    "\n",
    "# Create trace\n",
    "trace = go.Histogram(x = data.values,\n",
    "                     name = 'Ratings',\n",
    "                     xbins = dict(start = 0,\n",
    "                                  end = 200,\n",
    "                                  size = 2),\n",
    "                     marker = dict(color = '#db0000'))\n",
    "# Create layout\n",
    "layout = go.Layout(title = 'Distribution Of Ratings Per User (Clipped at 199)',\n",
    "                   xaxis = dict(title = 'Ratings Per User'),\n",
    "                   yaxis = dict(title = 'Count'),\n",
    "                   bargap = 0.2)\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a9722127be16657683963dcd0a39207c38fd699"
   },
   "source": [
    "The ratings per movie as well as the ratings per user both have nearly a perfect exponential decay. Only very few movies/users have many ratings.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db0a6e0a634d798509275e0613d7cf6bc6029255"
   },
   "source": [
    "# Filter Sparse MovieUsers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5b8f82cb62b0077f962d43153c86fd1d5c61f9a3"
   },
   "source": [
    "To reduce the dimensionality of the dataset I am filtering rarely rated movies and rarely rating users out.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe023d98fbd4327eb5bb88295c575c0012542521"
   },
   "outputs": [],
   "source": [
    "# Filter sparse movies\n",
    "min_movie_ratings = 10000\n",
    "filter_movies = (df['Movie'].value_counts()>min_movie_ratings)\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "# Filter sparse users\n",
    "min_user_ratings = 200\n",
    "filter_users = (df['User'].value_counts()>min_user_ratings)\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "# Actual filtering\n",
    "df_filterd = df[(df['Movie'].isin(filter_movies)) & (df['User'].isin(filter_users))]\n",
    "del filter_movies, filter_users, min_movie_ratings, min_user_ratings\n",
    "print('Shape User-Ratings unfiltered:\\t{}'.format(df.shape))\n",
    "print('Shape User-Ratings filtered:\\t{}'.format(df_filterd.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f2e44b3498fa98b7ae7f3c49bdaea5aadba1bf5"
   },
   "source": [
    "After filtering sparse movies and users about** 4.200.000** ratings are left.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "75f37272926105cd1c76c3d0ef52b69d392ab433"
   },
   "source": [
    "# Create Train&Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d4e095134c8f6336c32b89b4dab4f5f93f2ce78"
   },
   "outputs": [],
   "source": [
    "# Shuffle DataFrame\n",
    "df_filterd = df_filterd.drop('Date', axis=1).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Testingsize\n",
    "n = 100000\n",
    "\n",
    "# Split train- & testset\n",
    "df_train = df_filterd[:-n]\n",
    "df_test = df_filterd[-n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b0693f9220cf176753e43fc44508c5a72cce263"
   },
   "source": [
    "The trainset will be used to train all models and the ***testset ensures comparibility*** between all models with the ***RMSE*** metric.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d4f3612bc4d291b6feeec0bef395f6d9b78e7d26"
   },
   "source": [
    "---\n",
    "# User-Ratings To User-Movie-Matrix\n",
    "\n",
    "A **large, sparse matrix** will be created in this step. Each row will represent a user and its ratings and the columns are the movies.\n",
    "The interesting entries are the empty values in the matrix.\n",
    "\n",
    "**Empty values are unrated movies and could contain high values** and therefore should be good recommendations for the respective user.\n",
    "\n",
    "The objective is to estimate the empty values to help our users.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d963c0e3bf02505fdff45cca07bdbf725a3ac225"
   },
   "outputs": [],
   "source": [
    "# Create a user-movie matrix with empty values\n",
    "df_p = df_train.pivot_table(index='User', columns='Movie', values='Rating')\n",
    "print('Shape User-Movie-Matrix:\\t{}'.format(df_p.shape))\n",
    "df_p.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "43be425a64dbc8127434199abe4de0825fcd1952"
   },
   "source": [
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQn9TgAjTkbOSX5McNjk5EDmFyiuU1orzBEYvO-eOod34wS1l9V9Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b17eb6fe9e06272d19a6d9f9787199ca1b59d823"
   },
   "source": [
    "# Recommender Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a610a00624f6145fc4e48e64aa2accb8d1074e7"
   },
   "source": [
    "---\n",
    "\n",
    "# Mean Rating\n",
    "\n",
    "Computing the **mean rating for all movies creates a ranking**. The recommendation will be the same for all users and can be used if there is no information on the user.\n",
    "Variations of this approach can be separate rankings for each country/year/gender/... and to use them individually to recommend movies/items to the user.\n",
    "\n",
    "It has to be noted that this approach is **biased and favours movies with fewer ratings**, since large numbers of ratings tend to be less extreme in its mean ratings.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5423bc629c2a3a3dd4ba85cebcbd8b1d19071f95"
   },
   "outputs": [],
   "source": [
    "# Top n movies\n",
    "n = 10\n",
    "\n",
    "# Compute mean rating for all movies\n",
    "ratings_mean = df_p.mean(axis=0).sort_values(ascending=False).rename('Rating-Mean').to_frame()\n",
    "\n",
    "# Count ratings for all movies\n",
    "ratings_count = df_p.count(axis=0).rename('Rating-Count').to_frame()\n",
    "\n",
    "# Combine ratings_mean, ratings_count and movie_titles\n",
    "ranking_mean_rating = ratings_mean.head(n).join(ratings_count).join(movie_titles.drop('Year', axis=1))\n",
    "\n",
    "\n",
    "# Join labels and predictions\n",
    "df_prediction = df_test.set_index('Movie').join(ratings_mean)[['Rating', 'Rating-Mean']]\n",
    "y_true = df_prediction['Rating']\n",
    "y_pred = df_prediction['Rating-Mean']\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "\n",
    "\n",
    "# Create trace\n",
    "trace = go.Bar(x = ranking_mean_rating['Rating-Mean'],\n",
    "               text = ranking_mean_rating['Name'].astype(str) +': '+ ranking_mean_rating['Rating-Count'].astype(str) + ' Ratings',\n",
    "               textposition = 'outside',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               orientation = 'h',\n",
    "               y = list(range(1, n+1)))\n",
    "# Create layout\n",
    "layout = dict(title = 'Ranking Of Top {} Mean-Movie-Ratings: {:.4f} RMSE'.format(n, rmse),\n",
    "              xaxis = dict(title = 'Mean-Rating',\n",
    "                          range = (4.3, 4.55)),\n",
    "              yaxis = dict(title = 'Movie'))\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee5b009e135b3b623ae12ea6d35d12dc8ea452c8"
   },
   "source": [
    "---\n",
    "# Weighted Mean Rating\n",
    "To tackle the problem of the unstable mean with few ratings **e.g. IDMb uses a weighted rating**. Many good ratings outweigh few in this algorithm.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03c6ced6a912233903b68275e0623d224e0d94ce"
   },
   "outputs": [],
   "source": [
    "# Number of minimum votes to be considered\n",
    "m = 1000\n",
    "\n",
    "# Mean rating for all movies\n",
    "C = df_p.stack().mean()\n",
    "\n",
    "# Mean rating for all movies separatly\n",
    "R = df_p.mean(axis=0).values\n",
    "\n",
    "# Rating count for all movies separatly\n",
    "v = df_p.count().values\n",
    "\n",
    "\n",
    "# Weighted formula to compute the weighted rating\n",
    "weighted_score = (v/ (v+m) *R) + (m/ (v+m) *C)\n",
    "# Sort ids to ranking\n",
    "weighted_ranking = np.argsort(weighted_score)[::-1]\n",
    "# Sort scores to ranking\n",
    "weighted_score = np.sort(weighted_score)[::-1]\n",
    "# Get movie ids\n",
    "weighted_movie_ids = df_p.columns[weighted_ranking]\n",
    "\n",
    "\n",
    "# Join labels and predictions\n",
    "df_prediction = df_test.set_index('Movie').join(pd.DataFrame(weighted_score, index=weighted_movie_ids, columns=['Prediction']))[['Rating', 'Prediction']]\n",
    "y_true = df_prediction['Rating']\n",
    "y_pred = df_prediction['Prediction']\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "df_plot = pd.DataFrame(weighted_score[:n], columns=['Rating'])\n",
    "df_plot.index = weighted_movie_ids[:10]\n",
    "ranking_weighted_rating = df_plot.join(ratings_count).join(movie_titles)\n",
    "del df_plot\n",
    "\n",
    "\n",
    "# Create trace\n",
    "trace = go.Bar(x = ranking_weighted_rating['Rating'],\n",
    "               text = ranking_weighted_rating['Name'].astype(str) +': '+ ranking_weighted_rating['Rating-Count'].astype(str) + ' Ratings',\n",
    "               textposition = 'outside',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               orientation = 'h',\n",
    "               y = list(range(1, n+1)))\n",
    "# Create layout\n",
    "layout = dict(title = 'Ranking Of Top {} Weighted-Movie-Ratings: {:.4f} RMSE'.format(n, rmse),\n",
    "              xaxis = dict(title = 'Weighted Rating',\n",
    "                          range = (4.15, 4.6)),\n",
    "              yaxis = dict(title = 'Movie'))\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc96d13a2a593c54262103abfb093d93306e9d55"
   },
   "source": [
    "The variable **\"m\" can be seen as regularizing parameter.** Changing it determines how much weight is put onto the movies with many ratings.\n",
    "Even if there is a better ranking the RMSE decreased slightly. There is a** trade-off between interpretability and predictive power.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5fa7fb88fc8c9e8d1d2ea0a4cd931cdc231d01ac"
   },
   "source": [
    "---\n",
    "\n",
    "# Cosine User-User Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "02f2cd6ccc947cb3f02e8b79b8d554b919d3ae64"
   },
   "source": [
    "Interpreting each row of the matrix as a vector, a similarity between all user-vectors can be computed. This enables us to find all similar users and to work on user-specific recommendations. **Recommending high rated movies of similar users** to a specific user seems reasonable.\n",
    "\n",
    "Since there are still empty values left in the matrix, we have to use a reliable way to impute a decent value. A simple first approach is to **fill in the mean of each user into the empty values**\n",
    "\n",
    "\n",
    "Afterwards the** ratings of all similar users will be weighted with their similarity score and the mean will be computed**. Filtering for the unrated movies of a user reveals the best recommendations.\n",
    "You can easily adapt this process to find similar items by computing the item-item similarity the same way. Since the matrix is mostly sparse and there are more users than items, this could be better for the RMSE score.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a606f0a02aeda5941bdef9bb35725f949e84125"
   },
   "outputs": [],
   "source": [
    "# User index for recommendation\n",
    "user_index = 0\n",
    "\n",
    "# Number of similar users for recommendation\n",
    "n_recommendation = 100\n",
    "\n",
    "# Plot top n recommendations\n",
    "n_plot = 10\n",
    "\n",
    "\n",
    "# Fill in missing values\n",
    "df_p_imputed = df_p.T.fillna(df_p.mean(axis=1)).T\n",
    "\n",
    "# Compute similarity between all users\n",
    "similarity = cosine_similarity(df_p_imputed.values)\n",
    "\n",
    "# Remove self-similarity from similarity-matrix\n",
    "similarity -= np.eye(similarity.shape[0])\n",
    "\n",
    "\n",
    "# Sort similar users by index\n",
    "similar_user_index = np.argsort(similarity[user_index])[::-1]\n",
    "# Sort similar users by score\n",
    "similar_user_score = np.sort(similarity[user_index])[::-1]\n",
    "\n",
    "\n",
    "# Get unrated movies\n",
    "unrated_movies = df_p.iloc[user_index][df_p.iloc[user_index].isna()].index\n",
    "\n",
    "# Weight ratings of the top n most similar users with their rating and compute the mean for each movie\n",
    "mean_movie_recommendations = (df_p_imputed.iloc[similar_user_index[:n_recommendation]].T * similar_user_score[:n_recommendation]).T.mean(axis=0)\n",
    "\n",
    "# Filter for unrated movies and sort results\n",
    "best_movie_recommendations = mean_movie_recommendations[unrated_movies].sort_values(ascending=False).to_frame().join(movie_titles)\n",
    "\n",
    "\n",
    "# Create user-id mapping\n",
    "user_id_mapping = {id:i for i, id in enumerate(df_p_imputed.index)}\n",
    "\n",
    "prediction = []\n",
    "# Iterate over all testset items\n",
    "for user_id in df_test['User'].unique():\n",
    "    \n",
    "    # Sort similar users by index\n",
    "    similar_user_index = np.argsort(similarity[user_id_mapping[user_id]])[::-1]\n",
    "    # Sort similar users by score\n",
    "    similar_user_score = np.sort(similarity[user_id_mapping[user_id]])[::-1]\n",
    "    \n",
    "    for movie_id in df_test[df_test['User']==user_id]['Movie'].values:\n",
    "\n",
    "        # Compute predicted score\n",
    "        score = (df_p_imputed.iloc[similar_user_index[:n_recommendation]][movie_id] * similar_user_score[:n_recommendation]).values.sum() / similar_user_score[:n_recommendation].sum()\n",
    "        prediction.append([user_id, movie_id, score])\n",
    "        \n",
    "\n",
    "# Create prediction DataFrame\n",
    "df_pred = pd.DataFrame(prediction, columns=['User', 'Movie', 'Prediction']).set_index(['User', 'Movie'])\n",
    "df_pred = df_test.set_index(['User', 'Movie']).join(df_pred)\n",
    "\n",
    "\n",
    "# Get labels and predictions\n",
    "y_true = df_pred['Rating'].values\n",
    "y_pred = df_pred['Prediction'].values\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_true=y_true, y_pred=y_pred))\n",
    "\n",
    "\n",
    "# Create trace\n",
    "trace = go.Bar(x = best_movie_recommendations.iloc[:n_plot, 0],\n",
    "               text = best_movie_recommendations['Name'],\n",
    "               textposition = 'inside',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               orientation = 'h',\n",
    "               y = list(range(1, n_plot+1)),\n",
    "               marker = dict(color = '#db0000'))\n",
    "# Create layout\n",
    "layout = dict(title = 'Ranking Of Top {} Recommended Movies For A User Based On Similarity: {:.4f} RMSE'.format(n_plot, rmse),\n",
    "              xaxis = dict(title = 'Recommendation-Rating',\n",
    "                           range = (4.1, 4.5)),\n",
    "              yaxis = dict(title = 'Movie'))\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ce49c038912fe442e31f92411ce4ce4d3fb8152"
   },
   "source": [
    "---\n",
    "# TFIDF MovieDescription Similarity\n",
    "\n",
    "If there is no historical data for a user or there is reliable metadata for each movie, it can be useful to** compare the metadata of the movies to find similar ones.**\n",
    "\n",
    "In this approch I will use the **movie description to create a TFIDF-matrix,** which counts and weights words in all descriptions, and compute a cosine similarity between all of those sparse text-vectors. This can easily be extended to more or different features if you like.\n",
    "\n",
    "Unfortunately it is impossible for this model to compute a **RMSE score**, since the model does not recommend the movies directly.\n",
    "In this way it is possible to find movies closly related to each other, but it is **hard to find movies of different genres/categories**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67363d6aa9a1abad1fa03b64897dea73d3748d55"
   },
   "outputs": [],
   "source": [
    "# Create tf-idf matrix for text comparison\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movie_metadata['overview'].dropna())\n",
    "\n",
    "\n",
    "# Compute cosine similarity between all movie-descriptions\n",
    "similarity = cosine_similarity(tfidf_matrix)\n",
    "# Remove self-similarity from matrix\n",
    "similarity -= np.eye(similarity.shape[0])\n",
    "\n",
    "\n",
    "# Get index of movie to find similar movies\n",
    "movie = 'Batman Begins'\n",
    "n_plot = 10\n",
    "index = movie_metadata.reset_index(drop=True)[movie_metadata.index==movie].index[0]\n",
    "\n",
    "# Get indices and scores of similar movies\n",
    "similar_movies_index = np.argsort(similarity[index])[::-1][:n_plot]\n",
    "similar_movies_score = np.sort(similarity[index])[::-1][:n_plot]\n",
    "\n",
    "# Get titles of similar movies\n",
    "similar_movie_titles = movie_metadata.iloc[similar_movies_index].index\n",
    "\n",
    "\n",
    "# Create trace\n",
    "trace = go.Bar(x = similar_movies_score,\n",
    "               text = similar_movie_titles,\n",
    "               textposition = 'inside',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               orientation = 'h',\n",
    "               y = list(range(1, n_plot+1)),\n",
    "               marker = dict(color = '#db0000'))\n",
    "# Create layout\n",
    "layout = dict(title = 'Ranking Of Top {} Most Similar Movie Descriptions For \"{}\"'.format(n_plot, movie),\n",
    "              xaxis = dict(title = 'Cosine TFIDF Description Similarity',\n",
    "                           range = (0, 0.4)),\n",
    "              yaxis = dict(title = 'Movie'))\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e368475d3b5414f64549242a8da679cacbf9bdd"
   },
   "source": [
    "---\n",
    "#  Matrix Factorisation-Keras And Gradient Descent\n",
    "\n",
    "The **user-movie rating matrix is high dimensional and sparse**, therefore I am going to reduce the dimensionality to represent the data in a dense form.\n",
    "\n",
    "**Using matrix factorisation a large matrix can be estimated/decomposed into two long but slim matrices**. With gradient descent it is possible to adjust these matrices to represent the given ratings. The **gradient descent algorithm finds latent variables which represent the underlying structure of the dataset.** Afterwards these latent variables can be used to reconstruct the original matrix and to predict the missing ratings for each user.\n",
    "\n",
    "In this case the model has not been trained to convergence and is not hyperparameter optimized.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b52a3d547fbcf76a904fbc2164b7301a1d04184"
   },
   "outputs": [],
   "source": [
    "# Create user- & movie-id mapping\n",
    "user_id_mapping = {id:i for i, id in enumerate(df_filterd['User'].unique())}\n",
    "movie_id_mapping = {id:i for i, id in enumerate(df_filterd['Movie'].unique())}\n",
    "\n",
    "\n",
    "# Create correctly mapped train- & testset\n",
    "train_user_data = df_train['User'].map(user_id_mapping)\n",
    "train_movie_data = df_train['Movie'].map(movie_id_mapping)\n",
    "\n",
    "test_user_data = df_test['User'].map(user_id_mapping)\n",
    "test_movie_data = df_test['Movie'].map(movie_id_mapping)\n",
    "\n",
    "\n",
    "# Get input variable-sizes\n",
    "users = len(user_id_mapping)\n",
    "movies = len(movie_id_mapping)\n",
    "embedding_size = 10\n",
    "\n",
    "\n",
    "##### Create model\n",
    "# Set input layers\n",
    "user_id_input = Input(shape=[1], name='user')\n",
    "movie_id_input = Input(shape=[1], name='movie')\n",
    "\n",
    "# Create embedding layers for users and movies\n",
    "user_embedding = Embedding(output_dim=embedding_size, \n",
    "                           input_dim=users,\n",
    "                           input_length=1, \n",
    "                           name='user_embedding')(user_id_input)\n",
    "movie_embedding = Embedding(output_dim=embedding_size, \n",
    "                            input_dim=movies,\n",
    "                            input_length=1, \n",
    "                            name='item_embedding')(movie_id_input)\n",
    "\n",
    "# Reshape the embedding layers\n",
    "user_vector = Reshape([embedding_size])(user_embedding)\n",
    "movie_vector = Reshape([embedding_size])(movie_embedding)\n",
    "\n",
    "# Compute dot-product of reshaped embedding layers as prediction\n",
    "y = Dot(1, normalize=False)([user_vector, movie_vector])\n",
    "\n",
    "# Setup model\n",
    "model = Model(inputs=[user_id_input, movie_id_input], outputs=y)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\n",
    "# Fit model\n",
    "model.fit([train_user_data, train_movie_data],\n",
    "          df_train['Rating'],\n",
    "          batch_size=256, \n",
    "          epochs=1,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n",
    "\n",
    "# Test model\n",
    "y_pred = model.predict([test_user_data, test_movie_data])\n",
    "y_true = df_test['Rating'].values\n",
    "\n",
    "#  Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
    "print('\\n\\nTesting Result With Keras Matrix-Factorization: {:.4f} RMSE'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5378eff41cf27da52afeb965a0add5e0915e1eb7"
   },
   "source": [
    "---\n",
    "# Deep Learning With Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2279f069fc842d80e42bedded7c178e2207acc6a"
   },
   "source": [
    "With its embedding layers this is similar to the matrix factorization approach above, but instead of using a fixed dot-product as recommendation we will utilize some **dense layers** so the network can find better combinations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "78fa00b97ab836b72e8835a2b4c737c196f1a8cd"
   },
   "outputs": [],
   "source": [
    "# Setup variables\n",
    "user_embedding_size = 20\n",
    "movie_embedding_size = 10\n",
    "\n",
    "\n",
    "##### Create model\n",
    "# Set input layers\n",
    "user_id_input = Input(shape=[1], name='user')\n",
    "movie_id_input = Input(shape=[1], name='movie')\n",
    "\n",
    "# Create embedding layers for users and movies\n",
    "user_embedding = Embedding(output_dim=user_embedding_size, \n",
    "                           input_dim=users,\n",
    "                           input_length=1, \n",
    "                           name='user_embedding')(user_id_input)\n",
    "movie_embedding = Embedding(output_dim=movie_embedding_size, \n",
    "                            input_dim=movies,\n",
    "                            input_length=1, \n",
    "                            name='item_embedding')(movie_id_input)\n",
    "\n",
    "# Reshape the embedding layers\n",
    "user_vector = Reshape([user_embedding_size])(user_embedding)\n",
    "movie_vector = Reshape([movie_embedding_size])(movie_embedding)\n",
    "\n",
    "# Concatenate the reshaped embedding layers\n",
    "concat = Concatenate()([user_vector, movie_vector])\n",
    "\n",
    "# Combine with dense layers\n",
    "dense = Dense(256)(concat)\n",
    "y = Dense(1)(dense)\n",
    "\n",
    "# Setup model\n",
    "model = Model(inputs=[user_id_input, movie_id_input], outputs=y)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\n",
    "# Fit model\n",
    "model.fit([train_user_data, train_movie_data],\n",
    "          df_train['Rating'],\n",
    "          batch_size=256, \n",
    "          epochs=1,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n",
    "\n",
    "# Test model\n",
    "y_pred = model.predict([test_user_data, test_movie_data])\n",
    "y_true = df_test['Rating'].values\n",
    "\n",
    "#  Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
    "print('\\n\\nTesting Result With Keras Deep Learning: {:.4f} RMSE'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bbe959aa13093d4df5e1121e420d817630cdbe63"
   },
   "source": [
    "---\n",
    "# Deep Hybrid System With Metadata And Keras\n",
    "One advantage of deep learning models is, that movie-metadata can easily be added to the model.\n",
    "I will **tf-idf transform** the short description of all movies to a sparse vector. The model will learn to reduce the dimensionality of this vector and how to combine metadata with the embedding of the **user-id and the movie-id**. In this way you can add any additional metadata to your own recommender.\n",
    "These kind of hybrid systems can learn how to reduce the impact of the cold start problem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e613267ec8e71203950c898d6f24f28a232d1c24",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create user- & movie-id mapping\n",
    "user_id_mapping = {id:i for i, id in enumerate(df['User'].unique())}\n",
    "movie_id_mapping = {id:i for i, id in enumerate(df['Movie'].unique())}\n",
    "\n",
    "# Use mapping to get better ids\n",
    "df['User'] = df['User'].map(user_id_mapping)\n",
    "df['Movie'] = df['Movie'].map(movie_id_mapping)\n",
    "\n",
    "\n",
    "##### Combine both datasets to get movies with metadata\n",
    "# Preprocess metadata\n",
    "tmp_metadata = movie_metadata.copy()\n",
    "tmp_metadata.index = tmp_metadata.index.str.lower()\n",
    "\n",
    "# Preprocess titles\n",
    "tmp_titles = movie_titles.drop('Year', axis=1).copy()\n",
    "tmp_titles = tmp_titles.reset_index().set_index('Name')\n",
    "tmp_titles.index = tmp_titles.index.str.lower()\n",
    "\n",
    "# Combine titles and metadata\n",
    "df_id_descriptions = tmp_titles.join(tmp_metadata).dropna().set_index('Id')\n",
    "df_id_descriptions['overview'] = df_id_descriptions['overview'].str.lower()\n",
    "del tmp_metadata,tmp_titles\n",
    "\n",
    "\n",
    "# Filter all ratings with metadata\n",
    "df_hybrid = df.drop('Date', axis=1).set_index('Movie').join(df_id_descriptions).dropna().drop('overview', axis=1).reset_index().rename({'index':'Movie'}, axis=1)\n",
    "\n",
    "\n",
    "# Split train- & testset\n",
    "n = 100000\n",
    "df_hybrid = df_hybrid.sample(frac=1).reset_index(drop=True)\n",
    "df_hybrid_train = df_hybrid[:1500000]\n",
    "df_hybrid_test = df_hybrid[-n:]\n",
    "\n",
    "\n",
    "# Create tf-idf matrix for text comparison\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_hybrid = tfidf.fit_transform(df_id_descriptions['overview'])\n",
    "\n",
    "\n",
    "# Get mapping from movie-ids to indices in tfidf-matrix\n",
    "mapping = {id:i for i, id in enumerate(df_id_descriptions.index)}\n",
    "\n",
    "train_tfidf = []\n",
    "# Iterate over all movie-ids and save the tfidf-vector\n",
    "for id in df_hybrid_train['Movie'].values:\n",
    "    index = mapping[id]\n",
    "    train_tfidf.append(tfidf_hybrid[index])\n",
    "    \n",
    "test_tfidf = []\n",
    "# Iterate over all movie-ids and save the tfidf-vector\n",
    "for id in df_hybrid_test['Movie'].values:\n",
    "    index = mapping[id]\n",
    "    test_tfidf.append(tfidf_hybrid[index])\n",
    "\n",
    "\n",
    "# Stack the sparse matrices\n",
    "train_tfidf = vstack(train_tfidf)\n",
    "test_tfidf = vstack(test_tfidf)\n",
    "\n",
    "\n",
    "##### Setup the network\n",
    "# Network variables\n",
    "user_embed = 10\n",
    "movie_embed = 10\n",
    "\n",
    "\n",
    "# Create two input layers\n",
    "user_id_input = Input(shape=[1], name='user')\n",
    "movie_id_input = Input(shape=[1], name='movie')\n",
    "tfidf_input = Input(shape=[24144], name='tfidf', sparse=True)\n",
    "\n",
    "# Create separate embeddings for users and movies\n",
    "user_embedding = Embedding(output_dim=user_embed,\n",
    "                           input_dim=len(user_id_mapping),\n",
    "                           input_length=1,\n",
    "                           name='user_embedding')(user_id_input)\n",
    "movie_embedding = Embedding(output_dim=movie_embed,\n",
    "                            input_dim=len(movie_id_mapping),\n",
    "                            input_length=1,\n",
    "                            name='movie_embedding')(movie_id_input)\n",
    "\n",
    "# Dimensionality reduction with Dense layers\n",
    "tfidf_vectors = Dense(128, activation='relu')(tfidf_input)\n",
    "tfidf_vectors = Dense(32, activation='relu')(tfidf_vectors)\n",
    "\n",
    "# Reshape both embedding layers\n",
    "user_vectors = Reshape([user_embed])(user_embedding)\n",
    "movie_vectors = Reshape([movie_embed])(movie_embedding)\n",
    "\n",
    "# Concatenate all layers into one vector\n",
    "both = Concatenate()([user_vectors, movie_vectors, tfidf_vectors])\n",
    "\n",
    "# Add dense layers for combinations and scalar output\n",
    "dense = Dense(512, activation='relu')(both)\n",
    "dense = Dropout(0.2)(dense)\n",
    "output = Dense(1)(dense)\n",
    "\n",
    "\n",
    "# Create and compile model\n",
    "model = Model(inputs=[user_id_input, movie_id_input, tfidf_input], outputs=output)\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\n",
    "# Train and test the network\n",
    "model.fit([df_hybrid_train['User'], df_hybrid_train['Movie'], train_tfidf],\n",
    "          df_hybrid_train['Rating'],\n",
    "          batch_size=1024, \n",
    "          epochs=2,\n",
    "          validation_split=0.1,\n",
    "          shuffle=True)\n",
    "\n",
    "y_pred = model.predict([df_hybrid_test['User'], df_hybrid_test['Movie'], test_tfidf])\n",
    "y_true = df_hybrid_test['Rating'].values\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
    "print('\\n\\nTesting Result With Keras Hybrid Deep Learning: {:.4f} RMSE'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e289420296d52ceb5afdd44e891a14390fe61064"
   },
   "source": [
    "# Exploring Python Libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "005cf599d0155f82844c61299144c1b2d9fe3ee1"
   },
   "source": [
    "# Surprise Library\n",
    "\n",
    "The surprise library was built for creating and analyzing recommender systems.\n",
    "It has to be mentioned that most of the built-in algorithms use some kind of the above approches. I am going to compare these algorithms to each other in this section using 3-fold crossvalidation. Since the algorithms and the dataset have a large memoryfootprint the comparison will be executed on a subsampled dataset which is not comparable to the above models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3fb0a33876b29dad35c797585d2a9e017b0dd9da"
   },
   "outputs": [],
   "source": [
    "# Load dataset into surprise specific data-structure\n",
    "data = sp.Dataset.load_from_df(df_filterd[['User', 'Movie', 'Rating']].sample(20000), sp.Reader())\n",
    "\n",
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [sp.SVD(), sp.SVDpp(), sp.SlopeOne(), sp.NMF(), sp.NormalPredictor(), sp.KNNBaseline(), sp.KNNBasic(), sp.KNNWithMeans(), sp.KNNWithZScore(), sp.BaselineOnly(), sp.CoClustering()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE', 'MAE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    \n",
    "    # Store data\n",
    "    benchmark.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "48fd5fbea9a82b61389e1c4ff57bba46f30da636"
   },
   "outputs": [],
   "source": [
    "# Store results\n",
    "surprise_results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse', ascending=False)\n",
    "\n",
    "# Get data\n",
    "data = surprise_results[['test_rmse', 'test_mae']]\n",
    "grid = data.values\n",
    "\n",
    "# Create axis labels\n",
    "x_axis = [label.split('_')[1].upper() for label in data.columns.tolist()]\n",
    "y_axis = data.index.tolist()\n",
    "\n",
    "x_label = 'Function'\n",
    "y_label = 'Algorithm'\n",
    "\n",
    "\n",
    "# Get annotations and hovertext\n",
    "hovertexts = []\n",
    "annotations = []\n",
    "for i, y_value in enumerate(y_axis):\n",
    "    row = []\n",
    "    for j, x_value in enumerate(x_axis):\n",
    "        annotation = grid[i, j]\n",
    "        row.append('Error: {:.3f}<br>{}: {}<br>{}: {}<br>Fit Time: {:.3f}s<br>Test Time: {:.3f}s'.format(annotation, y_label, y_value ,x_label, x_value, surprise_results.loc[y_value]['fit_time'], surprise_results.loc[y_value]['test_time']))\n",
    "        annotations.append(dict(x=x_value, y=y_value, text='{:.3f}'.format(annotation), ax=0, ay=0, font=dict(color='#000000')))\n",
    "    hovertexts.append(row)\n",
    "\n",
    "# Create trace\n",
    "trace = go.Heatmap(x = x_axis,\n",
    "                   y = y_axis,\n",
    "                   z = data.values,\n",
    "                   text = hovertexts,\n",
    "                   hoverinfo = 'text',\n",
    "                   colorscale = 'Picnic',\n",
    "                   colorbar = dict(title = 'Error'))\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(title = 'Crossvalidated Comparison Of Surprise Algorithms',\n",
    "                   xaxis = dict(title = x_label),\n",
    "                   yaxis = dict(title = y_label,\n",
    "                                tickangle = -40),\n",
    "                   annotations = annotations)\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9bec3af0735f92aa77adc8208bde015631f2983"
   },
   "source": [
    "# Conclusion\n",
    "There are many different ways to set up a recommender system and just like other machine learning algorithms it is very important to know which objective has to be optimized and therefore which layout should be choosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da3e207bcbbe62a8adb9bd6d4b8fb9d9f9026de9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs152)",
   "language": "python",
   "name": "cs152"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
